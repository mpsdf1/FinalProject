{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33b015-c8fe-49b4-b4a7-8109b257438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d989a1-a4cb-459f-99ce-2059dd0406ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model and generate Markdown table\n",
    "def eval_model_generate_markdown(y_test, y_pred,name):\n",
    "    # Define target class names\n",
    "    tclasses = ['Dropout', 'Graduate']\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred, target_names=tclasses, output_dict=True)\n",
    "\n",
    "    # Extract precision, recall, and F1-score for each class\n",
    "    precision_dropout = report['Dropout']['precision']\n",
    "    recall_dropout = report['Dropout']['recall']\n",
    "    f1_dropout = report['Dropout']['f1-score']\n",
    "\n",
    "    precision_graduate = report['Graduate']['precision']\n",
    "    recall_graduate = report['Graduate']['recall']\n",
    "    f1_graduate = report['Graduate']['f1-score']\n",
    "\n",
    "    # Extract accuracy and ROC-AUC score\n",
    "    accuracy = report['accuracy']\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # Generate Markdown table\n",
    "    markdown_table = f\"\"\"\n",
    "     ____________________________________________\n",
    "    | Class      | Precision | Recall | F1-Score |\n",
    "    |------------|-----------|--------|----------|\n",
    "    | Dropout    | {precision_dropout:.2f}      | {recall_dropout:.2f}   | {f1_dropout:.2f}     |\n",
    "    | Graduate   | {precision_graduate:.2f}      | {recall_graduate:.2f}   | {f1_graduate:.2f}     |\n",
    "    |------------|-----------|--------|----------|\n",
    "    | Accuracy   | {accuracy:.2f}      |          \n",
    "    | ROC-AUC    | {roc_auc:.3f}     |            \n",
    "    --------------------------\n",
    "    \"\"\"\n",
    "    cfname = \"Confusion Matrix - \" + name\n",
    "    fname = 'cf' + name + '.png'\n",
    "\n",
    "    # Visualize and save the confusion matrix\n",
    "    rf_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=rf_conf_matrix, display_labels=tclasses).plot(cmap='Blues', values_format='d')\n",
    "    plt.title(cfname)\n",
    "    plt.savefig(fname)\n",
    "    plt.show()\n",
    "\n",
    "    return markdown_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397da24c-de8e-4528-b541-610e2fb82fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot training and validation accuracy\n",
    "def plot_accuracy_loss(history,fname):\n",
    "    a = 'Accuracy'\n",
    "    t1 = 'Training and Validation Accuracy - ' + fname\n",
    "    t2 = 'Training and Validation Loss - '\n",
    "    b = 'Loss'\n",
    "    f1 = 'accu'+fname+'.png'\n",
    "    f2 = 'loss'+fname+'.png'\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(f1)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f2)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523eeb11-ce1c-4bd5-9a9f-267a45dd8a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
